# -*- coding: utf-8 -*-
"""Final Project Python for Data Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SoHs1cn4hYf4IBs_LjwcQOWchpAuP943

# Phase 1: Data Acquisition and Initial Exploration

## Load the Dataset
"""

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
df = pd.read_csv("netflix_titles.csv")

"""## Dataset Preview

"""

df.head()

"""## Dataset Dimensions

"""

df.shape

"""## Column Names

"""

## Column Names

df.columns

"""## Data Types and Missing Values

"""

df.info()
df.isnull().sum()

"""### Analytical Commentary

In this phase, the Netflix dataset was successfully loaded into the Python environment using Google Colab.
The dataset is provided as a single CSV file containing one data table with multiple rows and columns,
where each row represents a movie or a TV show and each column describes a specific attribute.

Initial exploration showed that the dataset includes a combination of textual and numerical variables.
Key variables of analytical interest include the type of content (Movie or TV Show),
the release year, and the rating, as these variables can support meaningful analysis and comparisons.

Furthermore, the inspection revealed the presence of missing values in several columns,
such as director and country. These data quality issues may affect the accuracy of further analysis
and will need to be addressed in the data cleaning phase.

# Phase 2: Numerical Analysis with NumPy

## Creating NumPy Arrays from Python Lists
"""

import numpy as np

release_year_list = df['release_year'].tolist()
release_year = np.array(release_year_list)

"""## Size and Shape of the Array

"""

print(np.size(release_year))
np.shape(release_year)

## Data Type of the Array

release_year.dtype

"""## Built-in Numerical Methods

"""

print(np.min(release_year))
print(np.max(release_year))
print(np.argmax(release_year))
np.argmin(release_year)

"""## Statistical Functions

"""

print(np.mean(release_year))
print(np.median(release_year))
print(np.std(release_year))

"""## Sorting and Unique Values

"""

print(np.sort(release_year))
np.unique(release_year)

"""## NumPy Indexing and Slicing

### NumPy Indexing
"""

print(release_year[0] )
print(release_year[5] )
print(release_year[-1])

"""### NumPy Slicing (Index-based)

"""

print(release_year[:10]  )
print(release_year[10:20] )
print(release_year[-5:]      )

"""### Slicing with Step

"""

print(release_year[::2]   )
release_year[:20:3]

"""### Boolean Indexing

"""

print(release_year[release_year >= 2018])
release_year[(release_year >= 2015) & (release_year <= 2020)]

"""### Selecting the Last Two Years

"""

latest_year = np.max(release_year)
release_year[release_year >= latest_year - 1]

"""### Numerical Analysis Commentary

In this phase, NumPy was used to perform numerical analysis on a relevant numerical attribute.
Array size and shape were examined to understand the structure of the data.
Indexing and slicing techniques were applied to extract specific values and subsets,
including condition-based filtering using Boolean indexing.
Statistical functions helped summarize the numerical characteristics of the dataset.

#Phase 3: Data Cleaning and Transformation

##Checking for Missing Values

## Handling Missing and Invalid Data
"""

# Step 1: Check for missing values in each column
missing_values = df.isnull().sum()
print("Missing values in each column:")
print(missing_values)
# Step 2: Handle missing values in textual columns
df['director'] = df['director'].fillna('Unknown')
df['country'] = df['country'].fillna('Unknown')
df['cast'] = df['cast'].fillna('Unknown')
# Step 3: Verify that missing values have been handled
print("\nMissing values after handling:")
print(df[['director', 'country', 'cast']].isnull().sum())

"""##Transforming Variables into Meaningful Formats"""

# Convert date_added column to datetime format
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')

# Extract numeric values from duration column
df['duration_numeric'] = df['duration'].str.extract('(\d+)').astype(float)

print("Variables have been transformed into meaningful formats.")

df['date_added'].dtype
df['date_added'].head()
df[['duration', 'duration_numeric']].head()
df['duration_numeric'].dtype

"""##Adjusting Variable Names and Data Types






"""

# Ensure release_year is integer
df['release_year'] = df['release_year'].astype(int)

# Standardize column names
df.columns = df.columns.str.lower().str.replace(' ', '_')

print("Variable names and data types have been adjusted.")

"""##Refining the Dataset (Duplicate Records(

"""

rows_before = df.shape[0]

print("Duplicate Records Analysis")
print("=" * 40)
print(f"Total number of rows before cleaning: {rows_before}")

num_duplicates = df.duplicated().sum()
print(f"Number of duplicate rows detected: {num_duplicates}")

if num_duplicates > 0:
    print("\nWarning: Duplicate records were found.")
    print("Displaying duplicate rows:\n")

    duplicate_rows = df[df.duplicated(keep=False)]
    display(duplicate_rows)

    df = df.drop_duplicates(keep='first')

    rows_after = df.shape[0]
    removed = rows_before - rows_after

    print("\nDuplicate records have been removed.")
    print(f"Total number of rows after cleaning: {rows_after}")
    print(f"Total duplicate rows removed: {removed}")

else:
    print("\nNo duplicate records found. The dataset is clean.")

"""###### Data Cleaning and Transformation Commentary

In this phase, data cleaning and transformation techniques were applied
to improve the accuracy, consistency, and usability of the dataset.
Missing and invalid values were handled appropriately, variables were transformed
into meaningful formats, data types were standardized, and duplicate records
were identified and removed. These steps ensure that the dataset is clean
and reliable for further analysis.

#Phase 4: Feature Engineering

##Feature 1: content_type_encoded
"""

# Purpose:
# Convert the categorical 'type' column into a numerical feature
# Movie -> 1
# TV Show -> 0
# This makes the data easier to analyze numerically

print("Preview before creating the feature:")
print(df['type'].head())

df['content_type_encoded'] = df['type'].apply(
    lambda x: 1 if x == 'Movie' else 0
)

print("\nPreview after creating the feature:")
print(df[['type', 'content_type_encoded']].head())

print("\nFeature 'content_type_encoded' created successfully.")

"""##Feature 2: year_added"""

# Purpose:
# Extract the year from the 'date_added' column
# This allows time-based analysis of content additions

df['year_added'] = df['date_added'].dt.year

print("Preview of the new feature 'year_added':")
print(df[['date_added', 'year_added']].head())

print("\nFeature 'year_added' created successfully.")

"""##Feature 4: duration_category"""

# Purpose:
# Categorize content duration into meaningful groups
# Short: < 60
# Medium: 60 - 120
# Long: > 120

def categorize_duration(value):
    if value < 60:
        return 'Short'
    elif value <= 120:
        return 'Medium'
    else:
        return 'Long'

df['duration_category'] = df['duration_numeric'].apply(categorize_duration)

print("Preview of the new feature 'duration_category':")
print(df[['duration_numeric', 'duration_category']].head(10))

print("\nFeature 'duration_category' created successfully.")

"""###### Feature Engineering Commentary

In this phase, several new features were created to enhance the analytical value
of the dataset. A numerical feature was derived from the content type to support
numerical analysis. Temporal features such as year_added and content_age were
created to enable time-based insights. Additionally, content duration was
categorized into meaningful groups to simplify interpretation.
These engineered features provide deeper insights and improve the dataset’s
analytical depth.

#Phase 5: Data Selection, Aggregation, and Reshaping

##Phase 5: Data Selection, Aggregation, and Reshaping
"""

# Select only movies from the dataset
movies_df = df[df['type'] == 'Movie']

print("Number of movies:", movies_df.shape[0])
movies_df.head()

"""
##Aggregation: Summary Statistics"""

# Calculate average movie duration
average_duration = movies_df['duration_numeric'].mean()

print("Average movie duration (minutes):", average_duration)

"""## Grouping for Comparative Analysis"""

# Count content by type
content_by_type = df.groupby('type').size()

print("Content count by type:")
print(content_by_type)

# Average duration by duration category
avg_duration_by_category = movies_df.groupby('duration_category')['duration_numeric'].mean()

print("Average duration by category:")
print(avg_duration_by_category)

"""##Reshaping the Data (Pivot Table)

"""

# Create a pivot table for content count by type and year_added
pivot_table = pd.pivot_table(
    df,
    values='title',
    index='year_added',
    columns='type',
    aggfunc='count'
)

pivot_table.head(20
                 )

"""##### Data Selection, Aggregation, and Reshaping Commentary

In this phase, the dataset was explored through selection, aggregation, and reshaping
techniques to extract meaningful patterns and summaries.
Relevant subsets of the data were selected to focus the analysis, such as isolating
movie content.
Aggregation techniques were applied to compute summary statistics, including average
durations and content counts across categories.
Grouping operations enabled comparative analysis between different content types
and duration categories.
Additionally, a pivot table was created to reshape the dataset and provide a clear
comparison of content distribution over time.
These results reveal differences between movies and TV shows and highlight trends
in content availability across years.

#Phase 6: Data Visualization with Matplotlib

##Visualization: Monthly Netflix Content Additions (Line Chart)
Description

This visualization shows the number of titles added to Netflix per month over time.

Justification of Visualization Choice

A line chart was selected because the data represents a time series. This type of visualization is effective for identifying trends, growth patterns, and fluctuations over time.

Analytical Insight

The visualization reveals an overall increasing trend in the number of titles added to Netflix, especially after 2015. This indicates Netflix’s rapid expansion and increased investment in content production and acquisition. Periods of decline may reflect external factors such as production slowdowns or strategic changes in content release.
"""

df.columns

import pandas as pd
import matplotlib.pyplot as plt
df.columns = df.columns.str.strip()
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')
df = df.dropna(subset=['date_added'])

df['year_month'] = df['date_added'].dt.to_period('M')


monthly_titles = df.groupby('year_month').size()
monthly_titles.index = monthly_titles.index.to_timestamp()

plt.figure(figsize=(14,6))
plt.plot(monthly_titles.index, monthly_titles.values, marker='o')
plt.xlabel("Month")
plt.ylabel("Number of Titles Added")
plt.title("Monthly Netflix Content Additions")
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig("monthly_netflix_titles.png")
plt.show()

"""###Technical Implementation Summary

The date_added column was converted to datetime format.

Data was grouped by year and month to calculate the number of titles added.

A line chart was generated using Matplotlib.

The visualization was saved as an external image file.

##Bar Chart 2: Top 10 Countries by Number of Titles
"""

# Top 10 countries
top_countries = (
    df['country']
    .dropna()
    .str.split(', ')
    .explode()
    .value_counts()
    .head(10)
    .sort_values()
)

# Horizontal bar chart
plt.figure(figsize=(10, 6))
top_countries.plot(kind='barh')
plt.title('Top 10 Countries by Netflix Content', fontsize=14, fontweight='bold')
plt.xlabel('Number of Titles')
plt.ylabel('Country')
plt.grid(axis='x', alpha=0.3)

# Add value labels
for i, v in enumerate(top_countries):
    plt.text(v, i, f' {v}', va='center', fontweight='bold')

plt.tight_layout()
plt.savefig("top_10_countries_netflix.png")
plt.show()

"""1️⃣ Description of the Visualization

This bar chart displays the top 10 countries based on the number of titles available on Netflix. Each bar represents a country, and the length of the bar corresponds to the total number of titles produced or associated with that country.

2️⃣ Justification of Visualization Choice

A horizontal bar chart was chosen because it is effective for comparing values across multiple categories. Since country names are categorical and some labels are relatively long, the horizontal orientation improves readability and allows for a clear comparison between countries.

3️⃣ Analytical Insight

The visualization shows that the United States dominates Netflix content production by a large margin compared to other countries. India ranks second, reflecting the growing contribution of international content. The presence of multiple countries in the top 10 highlights Netflix’s global expansion strategy and its focus on diverse regional content.

4️⃣ Organization and Clarity

The chart is organized in ascending order, which makes it easy to identify the top contributors at a glance. Value labels were added to each bar to enhance clarity and allow precise comparison without needing to estimate values from the axis.

#Phase 7: Data Visualization with Seaborn

##Explore data distributions using statistical plots
"""

import seaborn as sns
import matplotlib.pyplot as plt

df = df.dropna(subset=['duration_numeric', 'type']).copy()

plt.figure(figsize=(8,6))
sns.boxplot(
    data=df,
    x='type',
    y='duration_numeric'
)

plt.title('Distribution of Content Duration by Type', fontsize=14, fontweight='bold')
plt.xlabel('Content Type')
plt.ylabel('Duration (Minutes)')
plt.tight_layout()
plt.show()

"""###Visualization: Distribution of Content Duration by Type

Description:
This box plot illustrates the distribution of content duration for Movies and TV Shows on Netflix.

Analytical Insight:
The visualization shows that movies generally have a higher median duration and a wider spread compared to TV Shows. TV Shows exhibit greater variability due to differences in episode counts and seasons. These distribution patterns are not immediately apparent from numerical summaries alone.

Justification:
A box plot was chosen because it effectively represents data distribution, central tendency, variability, and potential outliers for numerical variables across categories.

##Compare categorical and numerical variables visually
"""

import seaborn as sns
import matplotlib.pyplot as plt

df = df.dropna(subset=['type', 'duration_numeric']).copy()

plt.figure(figsize=(8,6))
sns.violinplot(
    data=df,
    x='type',
    y='duration_numeric'
)

plt.title('Comparison of Content Duration by Type', fontsize=14, fontweight='bold')
plt.xlabel('Content Type')
plt.ylabel('Duration (Minutes)')
plt.tight_layout()
plt.show()

"""###Visualization: Comparison of Content Duration by Type

Description:
This violin plot compares the distribution of content duration between Movies and TV Shows on Netflix.

Analytical Insight:
The visualization shows that movies tend to have longer and more concentrated durations, while TV Shows display a wider and more complex distribution. This reflects structural differences between single-length movies and episodic TV content. Such distribution patterns and density differences are not easily observed through numerical summaries alone.

Justification:
A violin plot was selected because it combines distribution shape and variability, making it effective for comparing numerical values across categorical groups.

##Construct at least one multi-variable or grid-based visualization
"""

import matplotlib.pyplot as plt

# ========= تجهيز البيانات =========

# Monthly titles trend
monthly_titles = (
    df.dropna(subset=['year_month'])
      .groupby('year_month')
      .size()
)
monthly_titles.index = monthly_titles.index.to_timestamp()

# Content type count
content_type_count = df['type'].value_counts()

# Rating count
rating_count = df['rating'].value_counts()

# ========= إنشاء الشكل مع Grid =========

fig = plt.figure(figsize=(15, 10))
gs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.3)

# --- Plot 1: كبير فوق ---
ax1 = fig.add_subplot(gs[0, :])
monthly_titles.plot(ax=ax1, marker='o', linewidth=2)
ax1.set_title('Monthly Netflix Content Additions', fontsize=14, fontweight='bold')
ax1.set_ylabel('Number of Titles')
ax1.grid(True, alpha=0.3)

# --- Plot 2: تحت يسار ---
ax2 = fig.add_subplot(gs[1, 0])
content_type_count.plot(kind='bar', ax=ax2)
ax2.set_title('Movies vs TV Shows', fontsize=12, fontweight='bold')
ax2.set_ylabel('Number of Titles')
ax2.grid(axis='y', alpha=0.3)

# --- Plot 3: تحت يمين ---
ax3 = fig.add_subplot(gs[1, 1])
rating_count.plot(kind='bar', ax=ax3)
ax3.set_title('Content Rating Distribution', fontsize=12, fontweight='bold')
ax3.set_ylabel('Number of Titles')
ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45)
ax3.grid(axis='y', alpha=0.3)

# --- عنوان عام ---
plt.suptitle(
    'Comprehensive Netflix Content Analysis',
    fontsize=16,
    fontweight='bold',
    y=0.98
)

plt.show()

"""###This grid-based visualization combines temporal trends and categorical comparisons in a single layout. The top plot highlights the growth of Netflix content over time, while the lower plots compare content types and rating distributions. Presenting multiple related views together reveals patterns and relationships that are not easily identified through individual numerical summaries.

ا

#Phase 8: Synthesis and Interpretation of Findings

##The analysis shows a clear growth in Netflix content over time, indicating continuous expansion of the platform. Movies represent a larger share of the catalog, while TV shows show greater variation in structure and duration. Visual analysis helped reveal patterns and differences between content types that are not immediately visible from numerical summaries alone. These insights highlight Netflix’s strategy to balance content diversity and audience engagement.
"""



"""# New Section"""